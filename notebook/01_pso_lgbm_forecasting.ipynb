{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSO-LightGBM Crude Oil Price Forecasting\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/fyp-project-ML/blob/main/notebook/01_pso_lgbm_forecasting.ipynb)\n",
    "\n",
    "## Quick Start for Google Colab\n",
    "\n",
    "1. **Upload your data**: Before running, upload `wti_price.csv` and `brent_price.csv` to one of these locations:\n",
    "   - `/content/drive/MyDrive/FYP PROJECT/DATASETS/` (recommended - persistent across sessions)\n",
    "   - `/content/data/` (temporary - will be deleted when runtime disconnects)\n",
    "\n",
    "2. **Run all cells**: Click `Runtime` â†’ `Run all` or press `Ctrl+F9`\n",
    "\n",
    "3. The notebook will automatically:\n",
    "   - Detect it's running in Colab\n",
    "   - Mount Google Drive (you'll need to authorize)\n",
    "   - Find your data files\n",
    "   - Install all required packages\n",
    "\n",
    "---\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "- Loads WTI and Brent crude oil price datasets\n",
    "- Performs exploratory data analysis (EDA)\n",
    "- Engineers time-series features\n",
    "- Optimizes LightGBM hyperparameters using Particle Swarm Optimization (PSO)\n",
    "- Trains forecasting models and evaluates performance\n",
    "- Generates visualizations and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aefif77/FYP_Project/blob/main/FYP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Environment Setup ----------\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "IS_COLAB = \"google.colab\" in sys.modules or \"COLAB_GPU\" in os.environ\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"ðŸ”µ Running in Google Colab\")\n",
    "    # Mount Google Drive to access datasets\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    \n",
    "    # Define candidate data directories for Colab\n",
    "    candidate_data_dirs = [\n",
    "        Path('/content/drive/MyDrive/FYP PROJECT/DATASETS'),\n",
    "        Path('/content/data'),\n",
    "    ]\n",
    "else:\n",
    "    print(\"ðŸ’» Running locally\")\n",
    "    repo_dir = Path.cwd()\n",
    "    \n",
    "    # Ensure libomp is discoverable for LightGBM on macOS (Homebrew install)\n",
    "    libomp_lib_dir = Path(\"/opt/homebrew/opt/libomp/lib\")\n",
    "    if libomp_lib_dir.exists():\n",
    "        for env_var in (\"DYLD_LIBRARY_PATH\", \"LD_LIBRARY_PATH\", \"LIBRARY_PATH\"):\n",
    "            current = os.environ.get(env_var, \"\")\n",
    "            libomp_str = str(libomp_lib_dir)\n",
    "            if libomp_str not in current.split(\":\"):\n",
    "                os.environ[env_var] = f\"{libomp_str}:{current}\" if current else libomp_str\n",
    "    \n",
    "    # Define candidate data directories for local execution\n",
    "    candidate_data_dirs = [\n",
    "        repo_dir / \"data\",\n",
    "        repo_dir.parent / \"data\",\n",
    "    ]\n",
    "\n",
    "# Find the data directory\n",
    "data_dir = None\n",
    "for candidate in candidate_data_dirs:\n",
    "    if candidate.exists():\n",
    "        data_dir = candidate\n",
    "        print(f\"âœ… Found data directory: {data_dir}\")\n",
    "        break\n",
    "\n",
    "if data_dir is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"âŒ Could not locate the 'data' directory. Tried:\\n  - \"\n",
    "        + \"\\n  - \".join(str(p.resolve()) for p in candidate_data_dirs)\n",
    "        + \"\\n\\nFor Colab: Upload your CSV files to Google Drive or create /content/data/\"\n",
    "    )\n",
    "\n",
    "# ---------- Data Loading ----------\n",
    "# Try different filename patterns\n",
    "wti_candidates = [\n",
    "    data_dir / \"wti_price.csv\",\n",
    "    data_dir / \"WTI Crude Oil Price Dataset  - WTI Price Data (Dr. Marina).csv\",\n",
    "]\n",
    "brent_candidates = [\n",
    "    data_dir / \"brent_price.csv\",\n",
    "    data_dir / \"WTI Crude Oil Price Dataset  - BRENT Price Data (Dr.Marina).csv\",\n",
    "]\n",
    "\n",
    "wti_path = next((p for p in wti_candidates if p.exists()), None)\n",
    "brent_path = next((p for p in brent_candidates if p.exists()), None)\n",
    "\n",
    "if wti_path is None or brent_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        f\"âŒ Could not find WTI or Brent CSV files.\\n\"\n",
    "        f\"WTI tried: {[str(p) for p in wti_candidates]}\\n\"\n",
    "        f\"Brent tried: {[str(p) for p in brent_candidates]}\"\n",
    "    )\n",
    "\n",
    "wti = pd.read_csv(wti_path)\n",
    "brent = pd.read_csv(brent_path)\n",
    "\n",
    "# Maintain legacy variable names used later in the notebook\n",
    "wti_price = wti.copy()\n",
    "brent_price = brent.copy()\n",
    "\n",
    "print(f\"âœ… Data loaded successfully\")\n",
    "print(f\"   WTI: {wti_path.name} ({len(wti)} rows)\")\n",
    "print(f\"   Brent: {brent_path.name} ({len(brent)} rows)\")\n",
    "display(wti.head(3))\n",
    "display(brent.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWiL7e5N1ekq"
   },
   "source": [
    "# Alternative local setup (commented out - use cell above instead)\n",
    "# import os, pandas as pd\n",
    "# base_dir = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "# wti = pd.read_csv(os.path.join(base_dir, \"data\", \"wti_price.csv\"))\n",
    "# brent = pd.read_csv(os.path.join(base_dir, \"data\", \"brent_price.csv\"))\n",
    "# wti_price = wti.copy()\n",
    "# brent_price = brent.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjdSg8r199gf",
    "outputId": "e6803167-b492-4d13-dc1d-09a1069c1ea5"
   },
   "outputs": [],
   "source": [
    "# Google Drive mount is now handled in the first cell\n",
    "# No need to run this separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrDog25b-W-R",
    "outputId": "c510d384-bcf6-4f9f-d8a0-ca17c5711d8a"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQh5Wafb-ZBU"
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style='whitegrid')\n",
    "sns.set_context(context='paper',font_scale=1.5)\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L98vftXR-ZJW"
   },
   "outputs": [],
   "source": [
    "# Drive paths are now handled in the first cell\n",
    "# This cell is no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "IG0QMZEN-bpS",
    "outputId": "71118ad7-6e0d-4549-a2eb-c81e76fc3a39"
   },
   "outputs": [],
   "source": [
    "pd.concat([wti_price.head(), wti_price.tail()]) #5433 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tUtb5ru-bxM",
    "outputId": "486053a2-a6ef-43ba-e530-4b66e0d5fe84"
   },
   "outputs": [],
   "source": [
    "wti_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "IovjPBi9-b35",
    "outputId": "11eaf1d7-8426-44a6-ea97-4a2242086c66"
   },
   "outputs": [],
   "source": [
    "wti_price.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "HenZpXxM-cor",
    "outputId": "28126ed8-6d98-4d1b-da82-bea5d47c3b4b"
   },
   "outputs": [],
   "source": [
    "pd.concat([brent_price.head(), brent_price.tail()]) #5461 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-xbrJwlL-dzO",
    "outputId": "0aabaded-0183-4f5c-f19b-16f20866fabf"
   },
   "outputs": [],
   "source": [
    "brent_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "YoAKL3vr-d8u",
    "outputId": "4a4edc67-020c-4210-b89b-e143b6194e15"
   },
   "outputs": [],
   "source": [
    "brent_price.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "or4a6JLb-eFD",
    "outputId": "1b7836b5-55e5-4149-b7a8-f662e13e4f68"
   },
   "outputs": [],
   "source": [
    "# Convert the date to dateimte object\n",
    "wti_price['Date'] = pd.to_datetime(wti_price['Date'], format='%m/%d/%Y')\n",
    "\n",
    "print(wti_price['Date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "dncfUvSu-44P",
    "outputId": "202f2d3a-e9cf-4096-981d-af4cf19b594c"
   },
   "outputs": [],
   "source": [
    "wti_df = wti_price\n",
    "wti_df\n",
    "\n",
    "# Change the index of the Df as date index\n",
    "# wti_df.index = pd.date_range(start='02-04-2014', end='02-05-2024', freq='D')\n",
    "wti_df = wti_price.set_index('Date')\n",
    "wti_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAPXOWFS-8st",
    "outputId": "1308710c-afda-433e-e1d3-50d85b3c73e9"
   },
   "outputs": [],
   "source": [
    "# Convert the date to dateimte object\n",
    "brent_price['Date'] = pd.to_datetime(brent_price['Date'], format='%m/%d/%Y')\n",
    "\n",
    "print(brent_price['Date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "bhR5i287-85i",
    "outputId": "ea7fefc3-e7e0-4696-9572-57c328aa3e96"
   },
   "outputs": [],
   "source": [
    "brent_df = brent_price\n",
    "brent_df\n",
    "\n",
    "# Change the index of the Df as date index\n",
    "# wti_df.index = pd.date_range(start='02-04-2014', end='02-05-2024', freq='D')\n",
    "brent_df = brent_price.set_index('Date')\n",
    "brent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "HQybCWUh_EXe",
    "outputId": "f26ff367-a657-4a86-c419-d61de8b5adab"
   },
   "outputs": [],
   "source": [
    "# Time Series Plot of the WTI data\n",
    "fig_1 = wti_df.squeeze().plot(figsize=(35,10),markersize=10, markerfacecolor= 'darkblue',marker='.',grid=True)\n",
    "plt.legend(fontsize=23)\n",
    "plt.title(\"Figure 1: Spot price of WTI Crude Oil (Dollors per Barrel)\",fontsize=35)\n",
    "plt.xlabel(\"Year\", fontsize=31)\n",
    "plt.ylabel(\"Spot Price\",fontsize=31)\n",
    "plt.xticks(fontsize=27)\n",
    "plt.yticks(fontsize=27)\n",
    "plt.savefig('fig_1_WTI_ts.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "o8pNKDJM_Ed2",
    "outputId": "afb67d0c-55d9-457b-8c40-799fb60cc846"
   },
   "outputs": [],
   "source": [
    "# Time Series Plot of the Brent data\n",
    "fig_5 = brent_df.squeeze().plot(figsize=(35,10),markersize=10, markerfacecolor= 'darkblue',marker='.',grid=True)\n",
    "plt.legend(fontsize=23)\n",
    "plt.title(\"Figure 1: Spot price of BRENT Crude Oil (Dollors per Barrel)\",fontsize=35)\n",
    "plt.xlabel(\"Year\", fontsize=31)\n",
    "plt.ylabel(\"Spot Price\",fontsize=31)\n",
    "plt.xticks(fontsize=27)\n",
    "plt.yticks(fontsize=27)\n",
    "plt.savefig('fig_1_BRENT_ts.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLXojSaa1YLB"
   },
   "source": [
    "# **WTI CRUDE OIL PRICE FORECASTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "id": "hF3acd2KyWv_",
    "outputId": "95bc8b49-28a9-4a29-a3a9-7fec46621de7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "def show_missing(df, name):\n",
    "    print(f\"{name} missing values:\\n\", df.isna().sum(), \"\\n\")\n",
    "\n",
    "show_missing(wti_df, 'WTI')\n",
    "\n",
    "def detect_iqr_outliers_visual(df, col='Price', mult=1.5,\n",
    "                                covid_start='2020-03-01', covid_end='2020-07-31'):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure Date is the index and in datetime format\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Tag COVID-19 period\n",
    "    df['is_covid'] = ((df.index >= pd.to_datetime(covid_start)) &\n",
    "                      (df.index <= pd.to_datetime(covid_end))).astype(int)\n",
    "\n",
    "    # Calculate IQR on non-COVID data\n",
    "    non_covid_data = df[df['is_covid'] == 0]\n",
    "    Q1, Q3 = non_covid_data[col].quantile([0.25, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - mult * IQR, Q3 + mult * IQR\n",
    "\n",
    "    # Flag non-COVID outliers\n",
    "    df['is_outlier'] = ((df[col] < lower) | (df[col] > upper)) & (df['is_covid'] == 0)\n",
    "\n",
    "    # Cleaned data\n",
    "    df_cleaned = df[~df['is_outlier']].copy()\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(df.index, df[col], label='Price', alpha=0.6)\n",
    "    plt.scatter(df[df['is_outlier']].index, df[df['is_outlier']][col],\n",
    "                color='red', label='Outliers', zorder=5)\n",
    "    plt.axvspan(pd.to_datetime(covid_start), pd.to_datetime(covid_end),\n",
    "                color='orange', alpha=0.2, label='COVID-19 Period')\n",
    "    plt.title('WTI Crude Oil Price with Outliers')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Dropped {df['is_outlier'].sum()} non-COVID outliers. Final rows: {len(df_cleaned)}\")\n",
    "    return df_cleaned, df\n",
    "\n",
    "\n",
    "wti_clean, wti_flagged = detect_iqr_outliers_visual(wti_df, col='Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "id": "A0OmHNi74R50",
    "outputId": "dcea57a9-9d69-45e6-8d2a-6f49481e9109"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "def make_sliding_window_df(series, window_size):\n",
    "    df = pd.DataFrame()\n",
    "    for lag in range(window_size, 0, -1):\n",
    "        df[f'lag_{lag}'] = series.shift(lag)\n",
    "    df['target'] = series\n",
    "    return df.dropna()\n",
    "\n",
    "def normalize_and_split(dataframe, test_size=0.20, val_size=0.20, scale_target=False):\n",
    "    dataframe = dataframe.sort_index()\n",
    "    X = dataframe.drop('target', axis=1)\n",
    "    y = dataframe['target']\n",
    "    total_len = len(X)\n",
    "\n",
    "    test_len = int(total_len * test_size)\n",
    "    remaining = total_len - test_len\n",
    "    val_len = int(remaining * (val_size / (1 - test_size)))\n",
    "    train_len = total_len - test_len - val_len\n",
    "\n",
    "    if train_len + val_len + test_len != total_len:\n",
    "        train_len += total_len - (train_len + val_len + test_len)\n",
    "\n",
    "    # split\n",
    "    X_train = X.iloc[:train_len];   y_train = y.iloc[:train_len]\n",
    "    X_val   = X.iloc[train_len:train_len+val_len]; y_val   = y.iloc[train_len:train_len+val_len]\n",
    "    X_test  = X.iloc[train_len+val_len:];         y_test  = y.iloc[train_len+val_len:]\n",
    "\n",
    "    # scale X\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_s = scaler_X.fit_transform(X_train)\n",
    "    X_val_s   = scaler_X.transform(X_val)\n",
    "    X_test_s  = scaler_X.transform(X_test)\n",
    "\n",
    "    X_train_df = pd.DataFrame(X_train_s, index=X_train.index, columns=X_train.columns)\n",
    "    X_val_df   = pd.DataFrame(X_val_s,   index=X_val.index,   columns=X_val.columns)\n",
    "    X_test_df  = pd.DataFrame(X_test_s,  index=X_test.index,  columns=X_test.columns)\n",
    "\n",
    "    # scale y\n",
    "    if scale_target:\n",
    "        scaler_y = StandardScaler()\n",
    "        y_train_out = scaler_y.fit_transform(y_train.values.reshape(-1,1)).flatten()\n",
    "        y_val_out   = scaler_y.transform(y_val.values.reshape(-1,1)).flatten()\n",
    "        y_test_out  = scaler_y.transform(y_test.values.reshape(-1,1)).flatten()\n",
    "    else:\n",
    "        scaler_y    = None\n",
    "        y_train_out = y_train\n",
    "        y_val_out   = y_val\n",
    "        y_test_out  = y_test\n",
    "\n",
    "    print(\"\\n--- Dataset Split Summary ---\")\n",
    "    print(f\"Total samples: {total_len}\")\n",
    "    print(f\"Train: {len(X_train_df)} ({X_train_df.index[0].date()} â†’ {X_train_df.index[-1].date()})\")\n",
    "    print(f\"Val:   {len(X_val_df)} ({X_val_df.index[0].date()} â†’ {X_val_df.index[-1].date()})\")\n",
    "    print(f\"Test:  {len(X_test_df)} ({X_test_df.index[0].date()} â†’ {X_test_df.index[-1].date()})\")\n",
    "\n",
    "    return X_train_df, X_val_df, X_test_df, y_train_out, y_val_out, y_test_out, scaler_X, scaler_y\n",
    "\n",
    "lookback = 5  # sliding window length\n",
    "\n",
    "if 'wti_clean' not in locals() or 'Price' not in wti_clean.columns:\n",
    "    raise ValueError(\"wti_clean DataFrame with 'Price' column is required.\")\n",
    "\n",
    "price_series = wti_clean['Price']\n",
    "\n",
    "\n",
    "wti_feats2 = make_sliding_window_df(price_series, window_size=lookback)\n",
    "\n",
    "X_train_scaled_df, X_val_scaled_df, X_test_scaled_df, \\\n",
    "y_train, y_val, y_test, scaler_X, scaler_y = normalize_and_split(\n",
    "    wti_feats2,\n",
    "    test_size=0.20,\n",
    "    val_size=0.20,\n",
    "    scale_target=False\n",
    ")\n",
    "\n",
    "# assume price_series, X_train_scaled_df, X_val_scaled_df, X_test_scaled_df already exist\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# plot full series in light grey\n",
    "plt.plot(wti_clean.index, price_series.values, color='lightgrey', label='Full Series')\n",
    "\n",
    "# overlay train, val, test\n",
    "plt.plot(price_series.loc[X_train_scaled_df.index].index,\n",
    "         price_series.loc[X_train_scaled_df.index].values,\n",
    "         color='tab:blue', label='Train')\n",
    "\n",
    "plt.plot(price_series.loc[X_val_scaled_df.index].index,\n",
    "         price_series.loc[X_val_scaled_df.index].values,\n",
    "         color='tab:orange', label='Validation')\n",
    "\n",
    "plt.plot(price_series.loc[X_test_scaled_df.index].index,\n",
    "         price_series.loc[X_test_scaled_df.index].values,\n",
    "         color='tab:green', label='Test')\n",
    "\n",
    "plt.title('WTI Crude Oil Price with Train / Val / Test Splits')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X_train_raw = pd.DataFrame(\n",
    "    scaler_X.inverse_transform(X_train_scaled_df),\n",
    "    index=X_train_scaled_df.index,\n",
    "    columns=X_train_scaled_df.columns\n",
    ")\n",
    "\n",
    "raw_stats    = X_train_raw.agg(['mean', 'std']).T\n",
    "scaled_stats = X_train_scaled_df.agg(['mean', 'std']).T\n",
    "\n",
    "# 2. Combine into a single table\n",
    "summary = pd.DataFrame({\n",
    "    'Raw Mean':    raw_stats['mean'],\n",
    "    'Raw StdDev':  raw_stats['std'],\n",
    "    'Scaled Mean': scaled_stats['mean'],\n",
    "    'Scaled StdDev': scaled_stats['std'],\n",
    "})\n",
    "\n",
    "# 3. (Optional) round for readability\n",
    "summary = summary.round(3)\n",
    "\n",
    "# 4. Display\n",
    "print(summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSUfKCJ5_kcm",
    "outputId": "59201246-70c7-4031-db23-22f00863fb57"
   },
   "outputs": [],
   "source": [
    "!pip install pyswarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tFp5Pl6hCTcT",
    "outputId": "fa8a70db-cd42-4355-d927-90aa768ceb97"
   },
   "outputs": [],
   "source": [
    "# PSO-LGBM MODELLING CELL\n",
    "from lightgbm import LGBMRegressor\n",
    "from pyswarm import pso\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_cost_history = []\n",
    "\n",
    "def lgbm_objective(params):\n",
    "    \"\"\"\n",
    "    PSO objective for LightGBM: returns validation RMSE,\n",
    "    tracks best_rmse and best_cost_history, and prints when a new best is found.\n",
    "    \"\"\"\n",
    "    global best_rmse, best_cost_history\n",
    "\n",
    "    # Unpack your hyperparameters (order must match lb/ub in your PSO call)\n",
    "    n_estimators, learning_rate, max_depth, num_leaves, \\\n",
    "    min_child_samples, subsample, colsample_bytree, reg_alpha, reg_lambda = params\n",
    "\n",
    "    # Build model\n",
    "    model = LGBMRegressor(\n",
    "        n_estimators=int(n_estimators),\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=int(max_depth),\n",
    "        num_leaves=int(num_leaves),\n",
    "        min_child_samples=int(min_child_samples),\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "    # Train & validate\n",
    "    model.fit(X_train_scaled_df, y_train)\n",
    "    y_val_pred = model.predict(X_val_scaled_df)\n",
    "    rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    loss = rmse\n",
    "\n",
    "    # Update convergence history: always store the running minimum loss\n",
    "    if best_cost_history:\n",
    "        best_cost_history.append(min(loss, best_cost_history[-1]))\n",
    "    else:\n",
    "        best_cost_history.append(loss)\n",
    "\n",
    "    # If this is a new best, update and print\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        print(\n",
    "            f\"New best parameters: \"\n",
    "            f\"n_estimators={int(n_estimators)}, \"\n",
    "            f\"learning_rate={learning_rate:.4f}, \"\n",
    "            f\"max_depth={int(max_depth)}, \"\n",
    "            f\"num_leaves={int(num_leaves)}, \"\n",
    "            f\"min_child_samples={int(min_child_samples)}, \"\n",
    "            f\"subsample={subsample:.2f}, \"\n",
    "            f\"colsample_bytree={colsample_bytree:.2f}, \"\n",
    "            f\"reg_alpha={reg_alpha:.2f}, \"\n",
    "            f\"reg_lambda={reg_lambda:.2f} â†’ RMSE={rmse:.4f}\"\n",
    "        )\n",
    "\n",
    "    return loss\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "# Order: n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, subsample, colsample_bytree, reg_alpha, reg_lambda\n",
    "lb = [100, 0.001, 3, 8, 5, 0.5, 0.5, 0.0, 0.0]\n",
    "ub = [3000, 0.1, 32, 128, 50, 1.0, 1.0, 10.0, 10.0]\n",
    "\n",
    "print(\"Lower bounds (lb):\", lb)\n",
    "print(\"Upper bounds (ub):\", ub)\n",
    "\n",
    "# Define PSO parameters\n",
    "swarmsize = 50        # Number of particles in the swarm\n",
    "maxiter = 50          # Maximum number of iterations\n",
    "omega = 0.8          # Inertia weight [0,1] (default 0.8)\n",
    "phip = 1.5            # Cognitive coefficient (C1) (default 1.5)\n",
    "phig = 1.5            # Social coefficient (C2) (default 1.5)\n",
    "\n",
    "print(\"\\n--- PSO Parameters ---\")\n",
    "print(f\"Swarm size: {swarmsize}\")\n",
    "print(f\"Max iterations: {maxiter}\")\n",
    "print(f\"Inertia weight (omega): {omega}\")\n",
    "print(f\"Cognitive coefficient (phip/C1): {phip}\")\n",
    "print(f\"Social coefficient (phig/C2): {phig}\")\n",
    "\n",
    "\n",
    "# Run PSO without the callback argument\n",
    "best_hyperparameters, best_rmse = pso(\n",
    "    func=lgbm_objective,\n",
    "    lb=lb,\n",
    "    ub=ub,\n",
    "    swarmsize=swarmsize,\n",
    "    maxiter=maxiter,\n",
    "    omega=omega,          # Inertia weight\n",
    "    phip=phip,            # Cognitive coefficient (C1)\n",
    "    phig=phig,            # Social coefficient (C2)\n",
    "    debug = True\n",
    ")\n",
    "\n",
    "# Print PSO results\n",
    "print(\"\\n--- PSO Results ---\")\n",
    "print(\"Best Hyperparameters found:\", best_hyperparameters)\n",
    "print(\"Best RMSE found:\", best_rmse)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(best_cost_history, label='Best Cost per Iteration', color='blue', linewidth=2)  # Thicker curve\n",
    "plt.title('PSO Best Cost Over Iterations', fontweight='bold', fontsize=14)  # Adjustable font size for the title\n",
    "plt.xlabel('Iteration', fontweight='bold', fontsize=14)  # Bold and adjustable font size for X-axis\n",
    "plt.ylabel('Loss', fontweight='bold', fontsize=14)  # Bold and adjustable font size for Y-axis\n",
    "plt.xticks(fontweight='bold', fontsize=14)  # Bold and adjustable font size for X-axis ticks\n",
    "plt.yticks(fontweight='bold', fontsize=14)  # Bold and adjustable font size for Y-axis ticks\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 7) Train final model on full train + early stopping on val set\n",
    "\n",
    "# Correctly map PSO output to LGBM parameters and ensure correct types\n",
    "final_model_params = {\n",
    "    'n_estimators': int(round(best_hyperparameters[0])),\n",
    "    'learning_rate': float(best_hyperparameters[1]),\n",
    "    'max_depth': int(round(best_hyperparameters[2])),\n",
    "    'num_leaves': int(round(best_hyperparameters[3])),\n",
    "    'min_child_samples': int(round(best_hyperparameters[4])),\n",
    "    'subsample': float(best_hyperparameters[5]),\n",
    "    'colsample_bytree': float(best_hyperparameters[6]),\n",
    "    'reg_alpha': float(best_hyperparameters[7]),\n",
    "    'reg_lambda': float(best_hyperparameters[8]),\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "# Ensure num_leaves is at least 2\n",
    "if final_model_params['num_leaves'] < 2:\n",
    "    print(f\"Warning: PSO suggested num_leaves={final_model_params['num_leaves']}. Setting to minimum required value of 2.\")\n",
    "    final_model_params['num_leaves'] = 2\n",
    "\n",
    "# Ensure other integer parameters are valid if needed (e.g., >= 1)\n",
    "if final_model_params['max_depth'] < 1 and final_model_params['max_depth'] != -1:\n",
    "     print(f\"Warning: PSO suggested max_depth={final_model_params['max_depth']}. Setting to 1.\")\n",
    "     final_model_params['max_depth'] = 1\n",
    "if final_model_params['min_child_samples'] < 1:\n",
    "    print(f\"Warning: PSO suggested min_child_samples={final_model_params['min_child_samples']}. Setting to 1.\")\n",
    "    final_model_params['min_child_samples'] = 1\n",
    "if final_model_params['n_estimators'] < 1:\n",
    "    print(f\"Warning: PSO suggested n_estimators={final_model_params['n_estimators']}. Setting to 1.\")\n",
    "    final_model_params['n_estimators'] = 1\n",
    "\n",
    "fit_params = {}\n",
    "if 'n_iter_no_change' in final_model_params:\n",
    "    fit_params['n_iter_no_change'] = final_model_params.pop('n_iter_no_change')\n",
    "if 'validation_fraction' in final_model_params:\n",
    "     fit_params['validation_fraction'] = final_model_params.pop('validation_fraction')\n",
    "if 'tol' in final_model_params:\n",
    "     fit_params['tol'] = final_model_params.pop('tol')\n",
    "\n",
    "\n",
    "print(\"\\nâ†’ PSO-tuned hyperparameters (after adjustments):\")\n",
    "for k, v in final_model_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Initialize LGBMRegressor with the adjusted parameters\n",
    "final_model = LGBMRegressor(**final_model_params)\n",
    "\n",
    "# Use the separate validation set for early stopping\n",
    "final_callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=50, verbose=10),\n",
    "]\n",
    "\n",
    "# Train the model with early stopping on the validation set\n",
    "final_model.fit(\n",
    "    X_train_scaled_df, y_train,\n",
    "    eval_set=[(X_train_scaled_df, y_train), (X_val_scaled_df, y_val)], # Include training set here\n",
    "    eval_metric='rmse',\n",
    "    callbacks=final_callbacks\n",
    ")\n",
    "\n",
    "# Plot training/validation RMSE\n",
    "eval_results = final_model.evals_result_\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(eval_results['training']['rmse'], label='Training RMSE')\n",
    "plt.plot(eval_results['valid_1']['rmse'], label='Validation RMSE')\n",
    "plt.title('Training vs Validation RMSE')\n",
    "plt.xlabel('Boosting Round')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Evaluate on Training Set ---\n",
    "y_train_pred = final_model.predict(\n",
    "    X_train_scaled_df,\n",
    "    num_iteration=final_model.best_iteration_\n",
    ")\n",
    "train_rmse = sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "train_mae  = mean_absolute_error(y_train, y_train_pred)\n",
    "print(\"\\n=== PSO-tuned LGBM Training Set Performance ===\")\n",
    "print(f\"RMSE: {train_rmse:.4f}\")\n",
    "print(f\"MAE : {train_mae:.4f}\")\n",
    "\n",
    "# 8) Predict & evaluate on test set\n",
    "y_pred = final_model.predict(\n",
    "    X_test_scaled_df,\n",
    "    num_iteration=final_model.best_iteration_\n",
    ")\n",
    "\n",
    "test_rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "test_mae  = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== FINAL TEST PERFORMANCE (PSO-tuned LGBM) ===\")\n",
    "print(f\"RMSE: {test_rmse:.4f}\")\n",
    "print(f\"MAE : {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "id": "oHti4ko7O7Dp",
    "outputId": "c61e249f-7e61-4203-9c4b-1abac849ca1a"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# ACTUAL VS PREDICTED PLOT (PSO - LGBM)\n",
    "# =====================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error # Import metrics for clarity\n",
    "\n",
    "if not isinstance(y_test, pd.Series) or not isinstance(y_test.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_test is not a pandas Series with DatetimeIndex. Plotting might fail.\")\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_df, pd.DataFrame) and isinstance(X_test_scaled_df.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_df.index\n",
    "         print(\"Using index from X_test_scaled_df for plotting.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for plotting.\")\n",
    "else:\n",
    "    test_index = y_test.index\n",
    "\n",
    "y_pred = final_model.predict(X_test_scaled_df)\n",
    "\n",
    "y_pred_array = np.asarray(y_pred)\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred_array\n",
    "}, index=test_index)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(plot_df.index, plot_df['Actual'],\n",
    "         label='Actual Price', color='black', linewidth=2)\n",
    "plt.plot(plot_df.index, plot_df['Predicted'],\n",
    "         label='Predicted (PSO-LGBM)', color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.title('WTI Crude Oil: Actual vs Predicted Prices (PSO-LGBM)', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== PSO-LGBM Test Set Performance ===\")\n",
    "print(f\"RMSE: {sqrt(mean_squared_error(y_test, y_pred_array)):.4f}\")\n",
    "print(f\"MAE : {mean_absolute_error(y_test, y_pred_array):.4f}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_test, pd.Series) or not isinstance(y_test.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_test is not a pandas Series with DatetimeIndex. Cannot create plot_df.\")\n",
    "    # Attempt to use index from X_test_scaled_df if available\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_df, pd.DataFrame) and isinstance(X_test_scaled_df.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_df.index\n",
    "         print(\"Using index from X_test_scaled_df for DataFrame.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for creating the DataFrame.\")\n",
    "else:\n",
    "    test_index = y_test.index\n",
    "\n",
    "# Ensure y_pred is available as a numpy array or list\n",
    "if 'y_pred' not in locals():\n",
    "    raise ValueError(\"y_pred (predictions) are not available. Please run the PSO-LGBM prediction cell first.\")\n",
    "\n",
    "# Create a DataFrame with Actual and Predicted values using the correct index\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': test_index,\n",
    "    'Actual_Price': y_test.values,\n",
    "    'Predicted_Price_LGBM': y_pred\n",
    "})\n",
    "\n",
    "# Set 'Date' as the index for better representation, though not strictly necessary for CSV export\n",
    "results_df = results_df.set_index('Date')\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_path = '/content/drive/MyDrive/FYP PROJECT/WTI_PSOLGBM_DataPredictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(csv_path)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "id": "MWVTao9zqUBL",
    "outputId": "c7b389fb-a444-4387-f0a8-396da9476932"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Determine the number of lag features (lookback length)\n",
    "lookback_lgbm = X_train_scaled_df.shape[1]\n",
    "\n",
    "\n",
    "def run_lgbm_default(X_tr, y_tr, X_val, y_val, X_te, y_te):\n",
    "\n",
    "    model = LGBMRegressor()\n",
    "\n",
    "    # Measure training time with early stopping\n",
    "    start = time.time()\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "        eval_metric='rmse',\n",
    "    )\n",
    "    duration = time.time() - start\n",
    "    print(f\"Default LGBM training took {duration:.1f} seconds\\n\")\n",
    "\n",
    "    # Validation evaluation\n",
    "    y_val_pred = model.predict(X_val, num_iteration=model.best_iteration_)\n",
    "    rmse_val = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    mae_val = mean_absolute_error(y_val, y_val_pred)\n",
    "    print(\"=== Default LGBM Validation Performance ===\")\n",
    "    print(f\"Lookback (lag features): {lookback_lgbm}\")\n",
    "    print(f\"RMSE: {rmse_val:.4f}, MAE: {mae_val:.4f}\\n\")\n",
    "\n",
    "    y_train_pred = model.predict(X_train_scaled_df, num_iteration=model.best_iteration_)\n",
    "    rmse_val = sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    mae_val = mean_absolute_error(y_train, y_train_pred)\n",
    "    print(\"=== Default LGBM Training Performance ===\")\n",
    "    print(f\"Lookback (lag features): {lookback_lgbm}\")\n",
    "    print(f\"RMSE: {rmse_val:.4f}, MAE: {mae_val:.4f}\\n\")\n",
    "\n",
    "    # Test evaluation\n",
    "    y_test_pred = model.predict(X_te, num_iteration=model.best_iteration_)\n",
    "    rmse_test = sqrt(mean_squared_error(y_te, y_test_pred))\n",
    "    mae_test = mean_absolute_error(y_te, y_test_pred)\n",
    "    print(\"=== Default LGBM Test Performance ===\")\n",
    "    print(f\"Lookback (lag features): {lookback_lgbm}\")\n",
    "    print(f\"RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\\n\")\n",
    "\n",
    "    return model, y_val_pred, y_test_pred\n",
    "\n",
    "lgbm_model_default, y_val_pred_lgbm, y_test_pred_lgbm = run_lgbm_default(\n",
    "    X_train_scaled_df, y_train,\n",
    "    X_val_scaled_df, y_val,\n",
    "    X_test_scaled_df, y_test\n",
    ")\n",
    "\n",
    "evals = lgbm_model_default.evals_result_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(evals['training']['rmse'], label='Training RMSE')\n",
    "plt.plot(evals['valid_1']['rmse'], label='Validation RMSE')\n",
    "plt.title('Default LGBM: Training vs Validation RMSE')\n",
    "plt.xlabel('Boosting Round')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_test, pd.Series) or not isinstance(y_test.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_test is not a pandas Series with DatetimeIndex. Cannot create plot_df.\")\n",
    "    # Attempt to use index from X_test_scaled_df if available\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_df, pd.DataFrame) and isinstance(X_test_scaled_df.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_df.index\n",
    "         print(\"Using index from X_test_scaled_df for DataFrame.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for creating the DataFrame.\")\n",
    "else:\n",
    "    test_index = y_test.index\n",
    "\n",
    "# Ensure y_pred is available as a numpy array or list\n",
    "if 'y_pred' not in locals():\n",
    "    raise ValueError(\"y_pred (predictions) are not available. Please run the PSO-LGBM prediction cell first.\")\n",
    "\n",
    "# Create a DataFrame with Actual and Predicted values using the correct index\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': test_index,\n",
    "    'Actual_Price': y_test.values,\n",
    "    'Predicted_Price_LGBM': y_pred\n",
    "})\n",
    "\n",
    "# Set 'Date' as the index for better representation, though not strictly necessary for CSV export\n",
    "results_df = results_df.set_index('Date')\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_path = '/content/drive/MyDrive/FYP PROJECT/WTI_PSOLGBM_DataPredictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(csv_path)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29nJQs23f36H",
    "outputId": "77627f8f-82bc-40ad-e709-26a9f0e855a1"
   },
   "outputs": [],
   "source": [
    "#AdaBoost Modelling with RandomizedSearchCV for Comparison\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "lookback_ada = X_train_scaled_df.shape[1]\n",
    "param_dist_ada = {\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [0.05],\n",
    "    'estimator__max_depth': [15]\n",
    "}\n",
    "\n",
    "tscv_ada = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "base_est = DecisionTreeRegressor(random_state=42)\n",
    "ada = AdaBoostRegressor(estimator=base_est, random_state=42)\n",
    "\n",
    "search_ada = RandomizedSearchCV(\n",
    "    estimator           = ada,\n",
    "    param_distributions = param_dist_ada,\n",
    "    n_iter              = 50,\n",
    "    cv                  = tscv_ada,\n",
    "    scoring             = 'neg_root_mean_squared_error',\n",
    "    random_state        = 42,\n",
    "    n_jobs              = -1,\n",
    "    verbose             = 2\n",
    ")\n",
    "\n",
    "def run_ada_tscv(X_tr, y_tr, X_val, y_val, X_te, y_te):\n",
    "    start = time.time()\n",
    "    search_ada.fit(X_tr, y_tr)\n",
    "    print(f\"AdaBoost RandomizedSearchCV took {time.time() - start:.1f}s\\n\")\n",
    "\n",
    "    best_ada = search_ada.best_estimator_\n",
    "\n",
    "    # Evaluate on Validation Set\n",
    "    val_preds = best_ada.predict(X_val)\n",
    "    rmse_val = sqrt(mean_squared_error(y_val, val_preds))\n",
    "    mae_val = mean_absolute_error(y_val, val_preds)\n",
    "    print(\"=== AdaBoost Validation Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_val:.4f}, MAE: {mae_val:.4f}\")\n",
    "\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "    test_preds    = best_ada.predict(X_te)\n",
    "    rmse_test = sqrt(mean_squared_error(y_te, test_preds))\n",
    "    mae_test  = mean_absolute_error(y_te, test_preds)\n",
    "\n",
    "    print(f\"Number of lags (lookback): {lookback_ada}\")\n",
    "    print(\"=== AdaBoost Test Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}\")\n",
    "    print(\"Best AdaBoost parameters:\", search_ada.best_params_,\"\\n\")\n",
    "\n",
    "    return search_ada, best_ada, val_preds, test_preds\n",
    "\n",
    "ada_rand, best_ada, y_val_pred_ada, y_test_pred_ada   = run_ada_tscv(\n",
    "    X_train_scaled_df, y_train,\n",
    "    X_val_scaled_df, y_val,\n",
    "    X_test_scaled_df, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "id": "T2GGHApFUjef",
    "outputId": "3372a225-ebf2-430d-8238-589e60787077"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# ACTUAL VS PREDICTED PLOT (AdaBoost)\n",
    "# =====================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_test, pd.Series) or not isinstance(y_test.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_test is not a pandas Series with DatetimeIndex. Plotting might fail.\")\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_df, pd.DataFrame) and isinstance(X_test_scaled_df.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_df.index\n",
    "         print(\"Using index from X_test_scaled_df for plotting.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for plotting.\")\n",
    "else:\n",
    "    test_index = y_test.index\n",
    "\n",
    "preds = best_ada.predict(X_test_scaled_df)\n",
    "\n",
    "y_pred_array = np.asarray(preds)\n",
    "\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred_array\n",
    "}, index=test_index)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(plot_df.index, plot_df['Actual'],\n",
    "         label='Actual Price', color='black', linewidth=2)\n",
    "plt.plot(plot_df.index, plot_df['Predicted'],\n",
    "         label='Predicted (AdaBoost)', color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.title('WTI Crude Oil: Actual vs Predicted Prices (AdaBoost)', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== LGBM Test Set Performance ===\")\n",
    "print(f\"RMSE: {sqrt(mean_squared_error(y_test, y_pred_array)):.4f}\")\n",
    "print(f\"MAE : {mean_absolute_error(y_test, y_pred_array):.4f}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_test, pd.Series) or not isinstance(y_test.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_test is not a pandas Series with DatetimeIndex. Cannot create plot_df.\")\n",
    "    # Attempt to use index from X_test_scaled_df if available\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_df, pd.DataFrame) and isinstance(X_test_scaled_df.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_df.index\n",
    "         print(\"Using index from X_test_scaled_df for DataFrame.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for creating the DataFrame.\")\n",
    "else:\n",
    "    test_index = y_test.index\n",
    "\n",
    "# Ensure y_pred is available as a numpy array or list\n",
    "if 'preds' not in locals():\n",
    "    raise ValueError(\"preds (predictions) are not available. Please run the PSO-LGBM prediction cell first.\")\n",
    "\n",
    "# Create a DataFrame with Actual and Predicted values using the correct index\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': test_index,\n",
    "    'Predicted_Price_LGBM': preds\n",
    "})\n",
    "\n",
    "# Set 'Date' as the index for better representation, though not strictly necessary for CSV export\n",
    "results_df = results_df.set_index('Date')\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_path = '/content/drive/MyDrive/FYP PROJECT/WTI_AdaBoost_DataPredictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(csv_path)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FMGmU436Dg5c",
    "outputId": "dc052d5c-3c4d-47d7-d308-7ae6359931d2"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# 5) CatBoost Modelling with RandomizedSearchCV for Comparison\n",
    "\n",
    "lookback_cat = X_train_scaled_df.shape[1]\n",
    "param_dist_cat = {\n",
    "    'iterations': [100],\n",
    "    'depth':      [15],\n",
    "    'learning_rate': [0.05],\n",
    "}\n",
    "\n",
    "tscv_cat = TimeSeriesSplit(n_splits=5)\n",
    "cat_base = CatBoostRegressor(verbose=0, random_state=42)\n",
    "\n",
    "search_cat = RandomizedSearchCV(\n",
    "    estimator           = cat_base,\n",
    "    param_distributions = param_dist_cat,\n",
    "    n_iter              = 50,\n",
    "    cv                  = tscv_cat,\n",
    "    scoring             = 'neg_root_mean_squared_error',\n",
    "    random_state        = 42,\n",
    "    n_jobs              = -1,\n",
    "    verbose             = 1\n",
    ")\n",
    "\n",
    "def run_cat_tscv(X_tr, y_tr, X_val, y_val, X_te, y_te):\n",
    "    start = time.time()\n",
    "    search_cat.fit(X_tr, y_tr)\n",
    "    print(f\"CatBoost RandomizedSearchCV took {time.time() - start:.1f}s\\n\")\n",
    "\n",
    "    best_cat = search_cat.best_estimator_\n",
    "\n",
    "    # Evaluate on Validation Set\n",
    "    val_preds = best_cat.predict(X_val)\n",
    "    rmse_val = sqrt(mean_squared_error(y_val, val_preds))\n",
    "    mae_val = mean_absolute_error(y_val, val_preds)\n",
    "    print(\"=== CatBoost Validation Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_val:.4f}, MAE: {mae_val:.4f}\")\n",
    "\n",
    "    # Evaluate on Test Set\n",
    "    preds    = best_cat.predict(X_te)\n",
    "    rmse_cat = sqrt(mean_squared_error(y_te, preds))\n",
    "    mae_cat  = mean_absolute_error(y_te, preds)\n",
    "\n",
    "    print(f\"Number of lags (lookback): {lookback_cat}\")\n",
    "    print(\"=== CatBoost Test Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_cat:.4f}, MAE: {mae_cat:.4f}\")\n",
    "    print(\"Best CatBoost parameters:\", search_cat.best_params_,\"\\n\")\n",
    "\n",
    "    return search_cat, best_cat, val_preds\n",
    "\n",
    "cat_rand, best_cat, y_val_pred_cat   = run_cat_tscv(X_train_scaled_df, y_train, X_val_scaled_df, y_val, X_test_scaled_df, y_test)\n",
    "\n",
    "# =====================\n",
    "# ACTUAL VS PREDICTED PLOT (CatBoost)\n",
    "# =====================\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_test, pd.Series) or not isinstance(y_test.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_test is not a pandas Series with DatetimeIndex. Plotting might fail.\")\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_df, pd.DataFrame) and isinstance(X_test_scaled_df.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_df.index\n",
    "         print(\"Using index from X_test_scaled_df for plotting.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for plotting.\")\n",
    "else:\n",
    "    test_index = y_test.index\n",
    "\n",
    "preds = best_cat.predict(X_test_scaled_df)\n",
    "\n",
    "y_pred_array = np.asarray(preds)\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred_array\n",
    "}, index=test_index)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(plot_df.index, plot_df['Actual'],\n",
    "         label='Actual Price', color='black', linewidth=2)\n",
    "plt.plot(plot_df.index, plot_df['Predicted'],\n",
    "         label='Predicted (CatBoost)', color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.title('WTI Crude Oil: Actual vs Predicted Prices (CatBoost)', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== CatBoost Test Set Performance ===\")\n",
    "print(f\"RMSE: {sqrt(mean_squared_error(y_test, y_pred_array)):.4f}\")\n",
    "print(f\"MAE : {mean_absolute_error(y_test, y_pred_array):.4f}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_test, pd.Series) or not isinstance(y_test.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_test is not a pandas Series with DatetimeIndex. Cannot create plot_df.\")\n",
    "    # Attempt to use index from X_test_scaled_df if available\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_df, pd.DataFrame) and isinstance(X_test_scaled_df.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_df.index\n",
    "         print(\"Using index from X_test_scaled_df for DataFrame.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for creating the DataFrame.\")\n",
    "else:\n",
    "    test_index = y_test.index\n",
    "\n",
    "# Ensure y_pred is available as a numpy array or list\n",
    "if 'preds' not in locals():\n",
    "    raise ValueError(\"preds (predictions) are not available. Please run the PSO-LGBM prediction cell first.\")\n",
    "\n",
    "# Create a DataFrame with Actual and Predicted values using the correct index\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': test_index,\n",
    "    'Predicted_Price_LGBM': preds\n",
    "})\n",
    "\n",
    "# Set 'Date' as the index for better representation, though not strictly necessary for CSV export\n",
    "results_df = results_df.set_index('Date')\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_path = '/content/drive/MyDrive/FYP PROJECT/WTI_CatBoost_DataPredictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(csv_path)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7MStBS0gz44w",
    "outputId": "5ab55948-4913-4b8b-f0e1-baae7c981f01"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 6) XGBoost Modelling with RandomizedSearchCV for Comparison\n",
    "\n",
    "lookback_xgb = X_train_scaled_df.shape[1]\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [15],\n",
    "    'learning_rate': [0.05],\n",
    "}\n",
    "\n",
    "\n",
    "tscv_xgb = TimeSeriesSplit(n_splits=5)\n",
    "xgb_base = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "search_xgb = RandomizedSearchCV(\n",
    "    estimator           = xgb_base,\n",
    "    param_distributions = param_dist_xgb,\n",
    "    n_iter              = 50,\n",
    "    cv                  = tscv_xgb,\n",
    "    scoring             = 'neg_root_mean_squared_error',\n",
    "    random_state        = 42,\n",
    "    n_jobs              = -1,\n",
    "    verbose             = 1\n",
    ")\n",
    "\n",
    "def run_xgb_tscv(X_tr, y_tr, X_val, y_val, X_te, y_te):\n",
    "    start = time.time()\n",
    "    search_xgb.fit(X_tr, y_tr)\n",
    "    print(f\"XGBoost RandomizedSearchCV took {time.time() - start:.1f}s\\n\")\n",
    "\n",
    "    best_xgb = search_xgb.best_estimator_\n",
    "\n",
    "    # Evaluate on Validation Set\n",
    "    val_preds = best_xgb.predict(X_val)\n",
    "    rmse_val = sqrt(mean_squared_error(y_val, val_preds))\n",
    "    mae_val = mean_absolute_error(y_val, val_preds)\n",
    "    print(\"=== XGBoost Validation Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_val:.4f}, MAE: {mae_val:.4f}\")\n",
    "\n",
    "\n",
    "    preds    = best_xgb.predict(X_te)\n",
    "    rmse_xgb = sqrt(mean_squared_error(y_te, preds))\n",
    "    mae_xgb  = mean_absolute_error(y_te, preds)\n",
    "\n",
    "    print(f\"Number of lags (lookback): {lookback_xgb}\")\n",
    "    print(\"=== XGBoost Test Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_xgb:.4f}, MAE: {mae_xgb:.4f}\")\n",
    "    print(\"Best XGBoost parameters:\", search_xgb.best_params_,\"\\n\")\n",
    "\n",
    "    return search_xgb, best_xgb, val_preds\n",
    "\n",
    "xgb_rand, best_xgb, y_val_pred_xgb   = run_xgb_tscv(X_train_scaled_df, y_train, X_val_scaled_df, y_val, X_test_scaled_df, y_test)\n",
    "\n",
    "# =====================\n",
    "# ACTUAL VS PREDICTED PLOT (XGBoost)\n",
    "# =====================\n",
    "\n",
    "if not isinstance(y_test, pd.Series) or not isinstance(y_test.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_test is not a pandas Series with DatetimeIndex. Plotting might fail.\")\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_df, pd.DataFrame) and isinstance(X_test_scaled_df.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_df.index\n",
    "         print(\"Using index from X_test_scaled_df for plotting.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for plotting.\")\n",
    "else:\n",
    "    test_index = y_test.index\n",
    "\n",
    "preds = best_xgb.predict(X_test_scaled_df)\n",
    "\n",
    "y_pred_array = np.asarray(preds)\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred_array\n",
    "}, index=test_index)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(plot_df.index, plot_df['Actual'],\n",
    "         label='Actual Price', color='black', linewidth=2)\n",
    "plt.plot(plot_df.index, plot_df['Predicted'],\n",
    "         label='Predicted (XGBoost)', color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.title('WTI Crude Oil: Actual vs Predicted Prices (XGBoost)', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== XGBoost Test Set Performance ===\")\n",
    "print(f\"RMSE: {sqrt(mean_squared_error(y_test, y_pred_array)):.4f}\")\n",
    "print(f\"MAE : {mean_absolute_error(y_test, y_pred_array):.4f}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_test, pd.Series) or not isinstance(y_test.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_test is not a pandas Series with DatetimeIndex. Cannot create plot_df.\")\n",
    "    # Attempt to use index from X_test_scaled_df if available\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_df, pd.DataFrame) and isinstance(X_test_scaled_df.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_df.index\n",
    "         print(\"Using index from X_test_scaled_df for DataFrame.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for creating the DataFrame.\")\n",
    "else:\n",
    "    test_index = y_test.index\n",
    "\n",
    "# Ensure y_pred is available as a numpy array or list\n",
    "if 'preds' not in locals():\n",
    "    raise ValueError(\"preds (predictions) are not available. Please run the PSO-LGBM prediction cell first.\")\n",
    "\n",
    "# Create a DataFrame with Actual and Predicted values using the correct index\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': test_index,\n",
    "    'Predicted_Price_LGBM': preds\n",
    "})\n",
    "\n",
    "# Set 'Date' as the index for better representation, though not strictly necessary for CSV export\n",
    "results_df = results_df.set_index('Date')\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_path = '/content/drive/MyDrive/FYP PROJECT/WTI_XGBoost_DataPredictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(csv_path)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBNGuigE05rA"
   },
   "source": [
    "# **BRENT CRUDE PRICE FORECASTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "id": "MVIJKnRdF0l5",
    "outputId": "da95f1d6-9068-4683-b08a-ea3e1b52136e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def show_missing(df, name):\n",
    "    print(f\"{name} missing values:\\n\", df.isna().sum(), \"\\n\")\n",
    "\n",
    "show_missing(brent_df, 'BRENT')\n",
    "\n",
    "def detect_iqr_outliers_visual(df, col='Price', mult=1.5,\n",
    "                                covid_start='2020-03-01', covid_end='2020-07-31'):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure Date is the index and in datetime format\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Tag COVID-19 period\n",
    "    df['is_covid'] = ((df.index >= pd.to_datetime(covid_start)) &\n",
    "                      (df.index <= pd.to_datetime(covid_end))).astype(int)\n",
    "\n",
    "    # Calculate IQR on non-COVID data\n",
    "    non_covid_data = df[df['is_covid'] == 0]\n",
    "    Q1, Q3 = non_covid_data[col].quantile([0.25, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - mult * IQR, Q3 + mult * IQR\n",
    "\n",
    "    # Flag non-COVID outliers\n",
    "    df['is_outlier'] = ((df[col] < lower) | (df[col] > upper)) & (df['is_covid'] == 0)\n",
    "\n",
    "    # Cleaned data\n",
    "    df_cleaned = df[~df['is_outlier']].copy()\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(df.index, df[col], label='Price', alpha=0.6)\n",
    "    plt.scatter(df[df['is_outlier']].index, df[df['is_outlier']][col],\n",
    "                color='red', label='Outliers', zorder=5)\n",
    "    plt.axvspan(pd.to_datetime(covid_start), pd.to_datetime(covid_end),\n",
    "                color='orange', alpha=0.2, label='COVID-19 Period')\n",
    "    plt.title('BRENT Crude Oil Price with Outliers')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(col)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Dropped {df['is_outlier'].sum()} non-COVID outliers. Final rows: {len(df_cleaned)}\")\n",
    "    return df_cleaned, df\n",
    "\n",
    "brent_clean, brent_flagged = detect_iqr_outliers_visual(brent_df, col='Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eN7SY4u6G2to",
    "outputId": "2bf55458-b56c-4530-9944-d66d41acc23d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "def make_sliding_window_df(series, window_size):\n",
    "    \"\"\"\n",
    "    Creates a sliding window DataFrame from a single time series.\n",
    "\n",
    "    Args:\n",
    "        series (pd.Series): The input time series (should be a pandas Series).\n",
    "        window_size (int): The number of previous time steps to use as features.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with lagged features and the target.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for lag in range(window_size, 0, -1):\n",
    "        df[f'lag_{lag}'] = series.shift(lag)\n",
    "    df['target'] = series\n",
    "    return df.dropna()\n",
    "\n",
    "def normalize_and_split(dataframe, test_size=0.20, val_size=0.20, scale_target=False):\n",
    "\n",
    "    dataframe = dataframe.sort_index()\n",
    "\n",
    "    X = dataframe.drop('target', axis=1)\n",
    "    y = dataframe['target']\n",
    "\n",
    "    total_len = len(X)\n",
    "    test_len = int(total_len * test_size)\n",
    "    remaining_len = total_len - test_len\n",
    "    val_len = int(remaining_len * (val_size / (1 - test_size)))\n",
    "    train_len = total_len - test_len - val_len\n",
    "\n",
    "    current_sum = train_len + val_len + test_len\n",
    "    if current_sum != total_len:\n",
    "        train_len += (total_len - current_sum)\n",
    "\n",
    "\n",
    "    # Split: [train | val | test]\n",
    "    X_train = X.iloc[:train_len]\n",
    "    y_train = y.iloc[:train_len]\n",
    "\n",
    "    X_val = X.iloc[train_len:train_len + val_len]\n",
    "    y_val = y.iloc[train_len:train_len + val_len]\n",
    "\n",
    "    X_test = X.iloc[train_len + val_len:]\n",
    "    y_test = y.iloc[train_len + val_len:]\n",
    "\n",
    "    # Normalize features\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_val_scaled = scaler_X.transform(X_val)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "    X_train_scaled_df = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns)\n",
    "    X_val_scaled_df = pd.DataFrame(X_val_scaled, index=X_val.index, columns=X_val.columns)\n",
    "    X_test_scaled_df = pd.DataFrame(X_test_scaled, index=X_test.index, columns=X_test.columns)\n",
    "\n",
    "\n",
    "    if scale_target:\n",
    "        scaler_y = StandardScaler()\n",
    "        y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "        y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1)).flatten()\n",
    "        y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "        y_train_out, y_val_out, y_test_out = y_train_scaled, y_val_scaled, y_test_scaled\n",
    "    else:\n",
    "        scaler_y = None\n",
    "        y_train_out, y_val_out, y_test_out = y_train, y_val, y_test\n",
    "\n",
    "    print(\"\\n--- Lagged Feature Dataset Preview ---\")\n",
    "    if 'brent_feats' in locals():\n",
    "         print(brent_feats.head())\n",
    "\n",
    "\n",
    "    print(\"\\n--- Dataset Split Summary ---\")\n",
    "    print(f\"Total samples in lagged data: {total_len}\")\n",
    "    print(f\"Training samples: {len(X_train_scaled_df)} | Dates: {X_train_scaled_df.index[0].date()} â†’ {X_train_scaled_df.index[-1].date()}\")\n",
    "    print(f\"Validation samples: {len(X_val_scaled_df)} | Dates: {X_val_scaled_df.index[0].date()} â†’ {X_val_scaled_df.index[-1].date()}\")\n",
    "    print(f\"Test samples: {len(X_test_scaled_df)} | Dates: {X_test_scaled_df.index[0].date()} â†’ {X_test_scaled_df.index[-1].date()}\")\n",
    "\n",
    "    return (X_train_scaled_df, X_val_scaled_df, X_test_scaled_df,\n",
    "            y_train_out, y_val_out, y_test_out,\n",
    "            scaler_X, scaler_y)\n",
    "\n",
    "lookback = 5 # sliding window length\n",
    "\n",
    "\n",
    "if 'brent_clean' in locals() and isinstance(brent_clean, pd.DataFrame) and 'Price' in brent_clean.columns:\n",
    "     brent_price_series = brent_clean['Price']\n",
    "else:\n",
    "     raise ValueError(\"brent_clean DataFrame with 'Price' column is required.\")\n",
    "\n",
    "\n",
    "brent_feats = make_sliding_window_df(brent_price_series, window_size=lookback)\n",
    "\n",
    "\n",
    "X_train_scaled_bdf, X_val_scaled_bdf, X_test_scaled_bdf, y_btrain, y_bval, y_btest, scaler_bX, scaler_by = normalize_and_split(\n",
    "    brent_feats,\n",
    "    test_size=0.20,\n",
    "    val_size=0.20,\n",
    "    scale_target=False\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# plot full series in light grey\n",
    "plt.plot(brent_clean.index, brent_price_series.values, color='lightgrey', label='Full Series')\n",
    "\n",
    "# overlay train, val, test\n",
    "plt.plot(brent_price_series.loc[X_train_scaled_bdf.index].index,\n",
    "         brent_price_series.loc[X_train_scaled_bdf.index].values,\n",
    "         color='tab:blue', label='Train')\n",
    "\n",
    "plt.plot(brent_price_series.loc[X_val_scaled_bdf.index].index,\n",
    "         brent_price_series.loc[X_val_scaled_bdf.index].values,\n",
    "         color='tab:orange', label='Validation')\n",
    "\n",
    "plt.plot(brent_price_series.loc[X_test_scaled_bdf.index].index,\n",
    "         brent_price_series.loc[X_test_scaled_bdf.index].values,\n",
    "         color='tab:green', label='Test')\n",
    "\n",
    "plt.title('BRENT Crude Oil Price with Train / Val / Test Splits')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X_train_braw = pd.DataFrame(\n",
    "    scaler_X.inverse_transform(X_train_scaled_bdf),\n",
    "    index=X_train_scaled_bdf.index,\n",
    "    columns=X_train_scaled_bdf.columns\n",
    ")\n",
    "\n",
    "raw_stats_b    = X_train_braw.agg(['mean', 'std']).T\n",
    "scaled_stats_b = X_train_scaled_bdf.agg(['mean', 'std']).T\n",
    "\n",
    "# 2. Combine into a single table\n",
    "summary = pd.DataFrame({\n",
    "    'Raw Mean':    raw_stats_b['mean'],\n",
    "    'Raw StdDev':  raw_stats_b['std'],\n",
    "    'Scaled Mean': scaled_stats_b['mean'],\n",
    "    'Scaled StdDev': scaled_stats_b['std'],\n",
    "})\n",
    "\n",
    "# 3. (Optional) round for readability\n",
    "summary = summary.round(3)\n",
    "\n",
    "# 4. Display\n",
    "print(summary)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot PACF on the given axes\n",
    "plot_pacf(\n",
    "    price_series,\n",
    "    lags=30,\n",
    "    alpha=0.05,\n",
    "    zero=False,\n",
    "    method='ywm',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Zoom in on the relevant range\n",
    "ax.set_ylim(-0.2, 0.2)\n",
    "# Show every 2nd lag for readability\n",
    "ax.set_xticks(range(1, 5, 2))\n",
    "\n",
    "# Enhance titles and labels\n",
    "ax.set_title('Partial Autocorrelation Function of WTI Price (Lags 1â€“30)', fontsize=14)\n",
    "ax.set_xlabel('Lag (days)', fontsize=12)\n",
    "ax.set_ylabel('Partial Autocorrelation', fontsize=12)\n",
    "\n",
    "# Add grid lines\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Cj-x7N90Hj4s",
    "outputId": "6b1cbd5c-1e41-4461-dcde-9ef452d4dbdf"
   },
   "outputs": [],
   "source": [
    "# PSO-LGBM MODELLING CELL\n",
    "from lightgbm import LGBMRegressor\n",
    "from pyswarm import pso\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def lgbm_objective(hyperparameters):\n",
    "    # Extract hyperparameters (ensure the order matches the bounds defined later for PSO)\n",
    "    n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, subsample, colsample_bytree, reg_alpha, reg_lambda = hyperparameters\n",
    "\n",
    "    # Instantiate LGBMRegressor with the given hyperparameters\n",
    "    # Convert integer hyperparameters to int type\n",
    "    model = LGBMRegressor(\n",
    "        n_estimators=int(n_estimators),\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=int(max_depth),\n",
    "        num_leaves=int(num_leaves),\n",
    "        min_child_samples=int(min_child_samples),\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train_scaled_bdf, y_btrain)\n",
    "\n",
    "    # Make predictions on the validation data\n",
    "    y_val_bpred = model.predict(X_val_scaled_bdf)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = sqrt(mean_squared_error(y_bval, y_val_bpred))\n",
    "\n",
    "    return rmse\n",
    "\n",
    "print(\"lgbm_objective function defined.\")\n",
    "\n",
    "# Order: n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, subsample, colsample_bytree, reg_alpha, reg_lambda\n",
    "lb = [100, 0.001, 3, 8, 5, 0.5, 0.5, 0.0, 0.0]\n",
    "ub = [3000, 0.1, 20, 256, 50, 1.0, 1.0, 10.0, 10.0]\n",
    "\n",
    "print(\"Lower bounds (lb):\", lb)\n",
    "print(\"Upper bounds (ub):\", ub)\n",
    "\n",
    "# Define PSO parameters\n",
    "swarmsize = 50        # Number of particles in the swarm\n",
    "maxiter = 50          # Maximum number of iterations\n",
    "omega = 0.8          # Inertia weight [0,1] (default 0.8)\n",
    "phip = 1.5            # Cognitive coefficient (C1) (default 1.5)\n",
    "phig = 1.5            # Social coefficient (C2) (default 1.5)\n",
    "\n",
    "print(\"\\n--- PSO Parameters ---\")\n",
    "print(f\"Swarm size: {swarmsize}\")\n",
    "print(f\"Max iterations: {maxiter}\")\n",
    "print(f\"Inertia weight (omega): {omega}\")\n",
    "print(f\"Cognitive coefficient (phip/C1): {phip}\")\n",
    "print(f\"Social coefficient (phig/C2): {phig}\")\n",
    "\n",
    "# Initialize variables to track PSO convergence\n",
    "pso_history = {'best_cost': [], 'mean_cost': []}\n",
    "\n",
    "def pso_callback(swarm, swarm_cost):\n",
    "    \"\"\"Callback function to track PSO convergence\"\"\"\n",
    "    pso_history['best_cost'].append(np.min(swarm_cost))\n",
    "    pso_history['mean_cost'].append(np.mean(swarm_cost))\n",
    "    return False  # Return False to continue optimization\n",
    "\n",
    "# Run PSO with additional parameters\n",
    "best_hyperparameters, best_rmse = pso(\n",
    "    func=lgbm_objective,\n",
    "    lb=lb,\n",
    "    ub=ub,\n",
    "    swarmsize=swarmsize,\n",
    "    maxiter=maxiter,\n",
    "    omega=omega,          # Inertia weight\n",
    "    phip=phip,            # Cognitive coefficient (C1)\n",
    "    phig=phig,            # Social coefficient (C2)\n",
    ")\n",
    "\n",
    "# Plot PSO Convergence\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pso_history['best_cost'], 'b-', label='Best RMSE')\n",
    "plt.plot(pso_history['mean_cost'], 'r--', label='Mean RMSE')\n",
    "plt.title('PSO Convergence (omega={}, C1={}, C2={})'.format(omega, phip, phig))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(\"\\n--- PSO Results ---\")\n",
    "print(\"Best Hyperparameters found:\", best_hyperparameters)\n",
    "print(\"Best RMSE found:\", best_rmse)\n",
    "\n",
    "# 7) Train final model on full train + early stopping on val set\n",
    "\n",
    "# Correctly map PSO output to LGBM parameters and ensure correct types\n",
    "final_model_params = {\n",
    "    'n_estimators': int(round(best_hyperparameters[0])),\n",
    "    'learning_rate': float(best_hyperparameters[1]),\n",
    "    'max_depth': int(round(best_hyperparameters[2])),\n",
    "    'num_leaves': int(round(best_hyperparameters[3])),\n",
    "    'min_child_samples': int(round(best_hyperparameters[4])),\n",
    "    'subsample': float(best_hyperparameters[5]),\n",
    "    'colsample_bytree': float(best_hyperparameters[6]),\n",
    "    'reg_alpha': float(best_hyperparameters[7]),\n",
    "    'reg_lambda': float(best_hyperparameters[8]),\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "# Ensure num_leaves is at least 2\n",
    "if final_model_params['num_leaves'] < 2:\n",
    "    print(f\"Warning: PSO suggested num_leaves={final_model_params['num_leaves']}. Setting to minimum required value of 2.\")\n",
    "    final_model_params['num_leaves'] = 2\n",
    "\n",
    "# Ensure other integer parameters are valid if needed (e.g., >= 1)\n",
    "if final_model_params['max_depth'] < 1 and final_model_params['max_depth'] != -1:\n",
    "     print(f\"Warning: PSO suggested max_depth={final_model_params['max_depth']}. Setting to 1.\")\n",
    "     final_model_params['max_depth'] = 1\n",
    "if final_model_params['min_child_samples'] < 1:\n",
    "    print(f\"Warning: PSO suggested min_child_samples={final_model_params['min_child_samples']}. Setting to 1.\")\n",
    "    final_model_params['min_child_samples'] = 1\n",
    "if final_model_params['n_estimators'] < 1:\n",
    "    print(f\"Warning: PSO suggested n_estimators={final_model_params['n_estimators']}. Setting to 1.\")\n",
    "    final_model_params['n_estimators'] = 1\n",
    "\n",
    "fit_params = {}\n",
    "if 'n_iter_no_change' in final_model_params:\n",
    "    fit_params['n_iter_no_change'] = final_model_params.pop('n_iter_no_change')\n",
    "if 'validation_fraction' in final_model_params:\n",
    "     fit_params['validation_fraction'] = final_model_params.pop('validation_fraction')\n",
    "if 'tol' in final_model_params:\n",
    "     fit_params['tol'] = final_model_params.pop('tol')\n",
    "\n",
    "print(\"\\nâ†’ PSO-tuned hyperparameters (after adjustments):\")\n",
    "for k, v in final_model_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Initialize LGBMRegressor with the adjusted parameters\n",
    "final_model = LGBMRegressor(**final_model_params)\n",
    "\n",
    "# Use the separate validation set for early stopping\n",
    "final_callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=50, verbose=10),\n",
    "]\n",
    "\n",
    "# Train the model with early stopping on the validation set\n",
    "final_model.fit(\n",
    "    X_train_scaled_bdf, y_btrain,\n",
    "    eval_set=[(X_val_scaled_bdf, y_bval)],\n",
    "    eval_metric='rmse',\n",
    "    callbacks=final_callbacks\n",
    ")\n",
    "\n",
    "# --- Evaluate on Training Set ---\n",
    "y_train_bpred = final_model.predict(\n",
    "    X_train_scaled_bdf,\n",
    "    num_iteration=final_model.best_iteration_\n",
    ")\n",
    "train_rmse = sqrt(mean_squared_error(y_btrain, y_train_bpred))\n",
    "train_mae  = mean_absolute_error(y_btrain, y_train_bpred)\n",
    "print(\"\\n=== PSO-tuned LGBM Training Set Performance ===\")\n",
    "print(f\"RMSE: {train_rmse:.4f}\")\n",
    "print(f\"MAE : {train_mae:.4f}\")\n",
    "\n",
    "# 8) Predict & evaluate on test set\n",
    "y_pred = final_model.predict(\n",
    "    X_test_scaled_bdf,\n",
    "    num_iteration=final_model.best_iteration_\n",
    ")\n",
    "\n",
    "test_rmse = sqrt(mean_squared_error(y_btest, y_bpred))\n",
    "test_mae  = mean_absolute_error(y_btest, y_bpred)\n",
    "\n",
    "print(\"\\n=== FINAL TEST PERFORMANCE (PSO-tuned LGBM) ===\")\n",
    "print(f\"RMSE: {test_rmse:.4f}\")\n",
    "print(f\"MAE : {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "id": "I5QaZ60UJtno",
    "outputId": "53825f6c-cb37-46ea-ec25-ef89bca4a0c6"
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# ACTUAL VS PREDICTED PLOT (LGBM)\n",
    "# =====================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "if not isinstance(y_btest, pd.Series) or not isinstance(y_btest.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_btest is not a pandas Series with DatetimeIndex. Plotting might fail.\")\n",
    "    if 'X_test_scaled_bdf' in locals() and isinstance(X_test_scaled_bdf, pd.DataFrame) and isinstance(X_test_scaled_bdf.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_bdf.index\n",
    "         print(\"Using index from X_test_scaled_bdf for plotting.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for plotting.\")\n",
    "else:\n",
    "    test_index = y_btest.index\n",
    "\n",
    "y_bpred = final_model.predict(X_test_scaled_bdf)\n",
    "\n",
    "y_bpred_array = np.asarray(y_bpred)\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'Actual': y_btest.values,\n",
    "    'Predicted': y_bpred_array\n",
    "}, index=test_index)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(plot_df.index, plot_df['Actual'],\n",
    "         label='Actual Price', color='black', linewidth=2)\n",
    "plt.plot(plot_df.index, plot_df['Predicted'],\n",
    "         label='Predicted (PSO-LGBM)', color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.title('Brent Crude Oil: Actual vs Predicted Prices (PSO-LGBM)', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== LGBM Test Set Performance ===\")\n",
    "print(f\"RMSE: {sqrt(mean_squared_error(y_btest, y_bpred_array)):.4f}\")\n",
    "print(f\"MAE : {mean_absolute_error(y_btest, y_bpred_array):.4f}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_btest, pd.Series) or not isinstance(y_btest.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_btest is not a pandas Series with DatetimeIndex. Cannot create plot_bdf.\")\n",
    "    # Attempt to use index from X_test_scaled_df if available\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_bdf, pd.DataFrame) and isinstance(X_test_scaled_bdf.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_bdf.index\n",
    "         print(\"Using index from X_test_scaled_df for DataFrame.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for creating the DataFrame.\")\n",
    "else:\n",
    "    test_index = y_btest.index\n",
    "\n",
    "# Ensure y_pred is available as a numpy array or list\n",
    "if 'y_bpred' not in locals():\n",
    "    raise ValueError(\"y_bpred (predictions) are not available. Please run the PSO-LGBM prediction cell first.\")\n",
    "\n",
    "# Create a DataFrame with Actual and Predicted values using the correct index\n",
    "results_bdf = pd.DataFrame({\n",
    "    'Date': test_index,\n",
    "    'Predicted_Price_LGBM': y_bpred\n",
    "})\n",
    "\n",
    "# Set 'Date' as the index for better representation, though not strictly necessary for CSV export\n",
    "results_bdf = results_bdf.set_index('Date')\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_path = '/content/drive/MyDrive/FYP PROJECT/BRENT_PSOLGBM_DataPredictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_bdf.to_csv(csv_path)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n",
    "display(results_bdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XZ09dGLT2Y0b",
    "outputId": "daff2b2b-aeae-4660-effe-5f646e9621c5"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 4) AdaBoost Modelling with RandomizedSearchCV for Comparison\n",
    "\n",
    "lookback_ada = X_train_scaled_bdf.shape[1]\n",
    "param_dist_ada = {\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [0.1],\n",
    "    'estimator__max_depth': [3]\n",
    "}\n",
    "\n",
    "tscv_ada = TimeSeriesSplit(n_splits=5)\n",
    "base_est = DecisionTreeRegressor(random_state=42)\n",
    "ada = AdaBoostRegressor(estimator=base_est, random_state=42)\n",
    "\n",
    "search_ada = RandomizedSearchCV(\n",
    "    estimator           = ada,\n",
    "    param_distributions = param_dist_ada,\n",
    "    n_iter              = 30,\n",
    "    cv                  = tscv_ada,\n",
    "    scoring             = 'neg_root_mean_squared_error',\n",
    "    random_state        = 42,\n",
    "    n_jobs              = -1,\n",
    "    verbose             = 1\n",
    ")\n",
    "\n",
    "def run_ada_tscv(X_tr, y_tr, X_val, y_val, X_te, y_te):\n",
    "    start = time.time()\n",
    "    search_ada.fit(X_tr, y_tr)\n",
    "    print(f\"AdaBoost RandomizedSearchCV took {time.time() - start:.1f}s\\n\")\n",
    "\n",
    "    best_ada = search_ada.best_estimator_\n",
    "\n",
    "    val_preds = best_ada.predict(X_val)\n",
    "    rmse_val = sqrt(mean_squared_error(y_val, val_preds))\n",
    "    mae_val = mean_absolute_error(y_val, val_preds)\n",
    "    print(\"=== AdaBoost Validation Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_val:.4f}, MAE: {mae_val:.4f}\")\n",
    "\n",
    "    preds    = best_ada.predict(X_te)\n",
    "    rmse_ada = sqrt(mean_squared_error(y_te, preds))\n",
    "    mae_ada  = mean_absolute_error(y_te, preds)\n",
    "\n",
    "    print(f\"Number of lags (lookback): {lookback_ada}\")\n",
    "    print(\"=== AdaBoost Test Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_ada:.4f}, MAE: {mae_ada:.4f}\")\n",
    "    print(\"Best AdaBoost parameters:\", search_ada.best_params_,\"\\n\")\n",
    "\n",
    "    return search_ada, best_ada, val_preds\n",
    "\n",
    "ada_rand, best_ada, y_val_pred_ada   = run_ada_tscv(X_train_scaled_bdf, y_btrain, X_val_scaled_bdf, y_bval, X_test_scaled_bdf, y_btest)\n",
    "\n",
    "# =====================\n",
    "# ACTUAL VS PREDICTED PLOT (AdaBoost)\n",
    "# =====================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "if not isinstance(y_btest, pd.Series) or not isinstance(y_btest.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_btest is not a pandas Series with DatetimeIndex. Plotting might fail.\")\n",
    "    if 'X_test_scaled_bdf' in locals() and isinstance(X_test_scaled_bdf, pd.DataFrame) and isinstance(X_test_scaled_bdf.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_bdf.index\n",
    "         print(\"Using index from X_test_scaled_bdf for plotting.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for plotting.\")\n",
    "else:\n",
    "    test_index = y_btest.index\n",
    "\n",
    "preds = best_ada.predict(X_test_scaled_bdf)\n",
    "\n",
    "y_bpred_array = np.asarray(preds)\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'Actual': y_btest.values,\n",
    "    'Predicted': y_bpred_array\n",
    "}, index=test_index)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(plot_df.index, plot_df['Actual'],\n",
    "         label='Actual Price', color='black', linewidth=2)\n",
    "plt.plot(plot_df.index, plot_df['Predicted'],\n",
    "         label='Predicted (AdaBoost)', color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.title('BRENT Crude Oil: Actual vs Predicted Prices (AdaBoost)', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== AdaBoost Test Set Performance ===\")\n",
    "print(f\"RMSE: {sqrt(mean_squared_error(y_btest, y_bpred_array)):.4f}\")\n",
    "print(f\"MAE : {mean_absolute_error(y_btest, y_bpred_array):.4f}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_btest, pd.Series) or not isinstance(y_btest.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_btest is not a pandas Series with DatetimeIndex. Cannot create plot_bdf.\")\n",
    "    # Attempt to use index from X_test_scaled_df if available\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_bdf, pd.DataFrame) and isinstance(X_test_scaled_bdf.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_bdf.index\n",
    "         print(\"Using index from X_test_scaled_df for DataFrame.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for creating the DataFrame.\")\n",
    "else:\n",
    "    test_index = y_btest.index\n",
    "\n",
    "# Ensure y_pred is available as a numpy array or list\n",
    "if 'preds' not in locals():\n",
    "    raise ValueError(\"preds (predictions) are not available. Please run the PSO-LGBM prediction cell first.\")\n",
    "\n",
    "# Create a DataFrame with Actual and Predicted values using the correct index\n",
    "results_bdf = pd.DataFrame({\n",
    "    'Date': test_index,\n",
    "    'Actual_Price_LGBM': y_btest.values,\n",
    "    'Predicted_Price_LGBM': preds\n",
    "})\n",
    "\n",
    "# Set 'Date' as the index for better representation, though not strictly necessary for CSV export\n",
    "results_bdf = results_bdf.set_index('Date')\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_path = '/content/drive/MyDrive/FYP PROJECT/BRENT_AdaBoost_DataPredictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_bdf.to_csv(csv_path)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n",
    "display(results_bdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A1Kw1Oee4Cl7",
    "outputId": "b5bd3580-3a4f-43e7-de0c-ef500a12a13a"
   },
   "outputs": [],
   "source": [
    "# 5) CatBoost Modelling with RandomizedSearchCV for Comparison\n",
    "\n",
    "lookback_cat = X_train_scaled_bdf.shape[1]\n",
    "param_dist_cat = {\n",
    "    'iterations': [100],\n",
    "    'depth':      [3],\n",
    "    'learning_rate': [0.1],\n",
    "}\n",
    "\n",
    "tscv_cat = TimeSeriesSplit(n_splits=5)\n",
    "cat_base = CatBoostRegressor(verbose=0, random_state=42)\n",
    "\n",
    "search_cat = RandomizedSearchCV(\n",
    "    estimator           = cat_base,\n",
    "    param_distributions = param_dist_cat,\n",
    "    n_iter              = 30,\n",
    "    cv                  = tscv_cat,\n",
    "    scoring             = 'neg_root_mean_squared_error',\n",
    "    random_state        = 42,\n",
    "    n_jobs              = -1,\n",
    "    verbose             = 1\n",
    ")\n",
    "\n",
    "def run_cat_tscv(X_tr, y_tr, X_val, y_val, X_te, y_te):\n",
    "    start = time.time()\n",
    "    search_cat.fit(X_tr, y_tr)\n",
    "    print(f\"CatBoost RandomizedSearchCV took {time.time() - start:.1f}s\\n\")\n",
    "\n",
    "    best_cat = search_cat.best_estimator_\n",
    "\n",
    "    val_preds = best_cat.predict(X_val)\n",
    "    rmse_val = sqrt(mean_squared_error(y_val, val_preds))\n",
    "    mae_val = mean_absolute_error(y_val, val_preds)\n",
    "    print(\"=== CatBoost Validation Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_val:.4f}, MAE: {mae_val:.4f}\")\n",
    "\n",
    "    preds    = best_cat.predict(X_te)\n",
    "    rmse_cat = sqrt(mean_squared_error(y_te, preds))\n",
    "    mae_cat  = mean_absolute_error(y_te, preds)\n",
    "\n",
    "    print(f\"Number of lags (lookback): {lookback_cat}\")\n",
    "    print(\"=== CatBoost Test Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_cat:.4f}, MAE: {mae_cat:.4f}\")\n",
    "    print(\"Best CatBoost parameters:\", search_cat.best_params_,\"\\n\")\n",
    "\n",
    "    return search_cat, best_cat, val_preds\n",
    "\n",
    "cat_rand, best_cat, y_val_pred_cat   = run_cat_tscv(X_train_scaled_bdf, y_btrain, X_val_scaled_bdf, y_bval, X_test_scaled_bdf, y_btest)\n",
    "\n",
    "# =====================\n",
    "# ACTUAL VS PREDICTED PLOT (CatBoost)\n",
    "# =====================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "if not isinstance(y_btest, pd.Series) or not isinstance(y_btest.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_btest is not a pandas Series with DatetimeIndex. Plotting might fail.\")\n",
    "    if 'X_test_scaled_bdf' in locals() and isinstance(X_test_scaled_bdf, pd.DataFrame) and isinstance(X_test_scaled_bdf.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_bdf.index\n",
    "         print(\"Using index from X_test_scaled_bdf for plotting.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for plotting.\")\n",
    "else:\n",
    "    test_index = y_btest.index\n",
    "\n",
    "preds = best_cat.predict(X_test_scaled_bdf)\n",
    "\n",
    "y_bpred_array = np.asarray(preds)\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'Actual': y_btest.values,\n",
    "    'Predicted': y_bpred_array\n",
    "}, index=test_index)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(plot_df.index, plot_df['Actual'],\n",
    "         label='Actual Price', color='black', linewidth=2)\n",
    "plt.plot(plot_df.index, plot_df['Predicted'],\n",
    "         label='Predicted (CatBoost)', color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.title('BRENT Crude Oil: Actual vs Predicted Prices (CatBoost)', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== CatBoost Test Set Performance ===\")\n",
    "print(f\"RMSE: {sqrt(mean_squared_error(y_btest, y_bpred_array)):.4f}\")\n",
    "print(f\"MAE : {mean_absolute_error(y_btest, y_bpred_array):.4f}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_btest, pd.Series) or not isinstance(y_btest.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_btest is not a pandas Series with DatetimeIndex. Cannot create plot_bdf.\")\n",
    "    # Attempt to use index from X_test_scaled_df if available\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_bdf, pd.DataFrame) and isinstance(X_test_scaled_bdf.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_bdf.index\n",
    "         print(\"Using index from X_test_scaled_df for DataFrame.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for creating the DataFrame.\")\n",
    "else:\n",
    "    test_index = y_btest.index\n",
    "\n",
    "# Ensure y_pred is available as a numpy array or list\n",
    "if 'preds' not in locals():\n",
    "    raise ValueError(\"preds (predictions) are not available. Please run the PSO-LGBM prediction cell first.\")\n",
    "\n",
    "# Create a DataFrame with Actual and Predicted values using the correct index\n",
    "results_bdf = pd.DataFrame({\n",
    "    'Date': test_index,\n",
    "    'Predicted_Price_LGBM': preds\n",
    "})\n",
    "\n",
    "# Set 'Date' as the index for better representation, though not strictly necessary for CSV export\n",
    "results_bdf = results_bdf.set_index('Date')\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_path = '/content/drive/MyDrive/FYP PROJECT/BRENT_CatBoost_DataPredictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_bdf.to_csv(csv_path)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n",
    "display(results_bdf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RRAlfhWM4alX",
    "outputId": "40ca7fce-cbc1-4949-e623-1d1044336f8e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 6) XGBoost Modelling with RandomizedSearchCV for Comparison\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "lookback_xgb = X_train_scaled_bdf.shape[1]\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3],\n",
    "    'learning_rate': [0.1],\n",
    "}\n",
    "\n",
    "tscv_xgb = TimeSeriesSplit(n_splits=5)\n",
    "xgb_base = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "search_xgb = RandomizedSearchCV(\n",
    "    estimator           = xgb_base,\n",
    "    param_distributions = param_dist_xgb,\n",
    "    n_iter              = 30,\n",
    "    cv                  = tscv_xgb,\n",
    "    scoring             = 'neg_root_mean_squared_error',\n",
    "    random_state        = 42,\n",
    "    n_jobs              = -1,\n",
    "    verbose             = 1\n",
    ")\n",
    "\n",
    "def run_xgb_tscv(X_tr, y_tr, X_val, y_val, X_te, y_te):\n",
    "    start = time.time()\n",
    "    search_xgb.fit(X_tr, y_tr)\n",
    "    print(f\"XGBoost RandomizedSearchCV took {time.time() - start:.1f}s\\n\")\n",
    "\n",
    "    best_xgb = search_xgb.best_estimator_\n",
    "\n",
    "    val_preds = best_xgb.predict(X_val)\n",
    "    rmse_val = sqrt(mean_squared_error(y_val, val_preds))\n",
    "    mae_val = mean_absolute_error(y_val, val_preds)\n",
    "    print(\"=== XGBoost Validation Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_val:.4f}, MAE: {mae_val:.4f}\")\n",
    "\n",
    "\n",
    "    preds    = best_xgb.predict(X_te)\n",
    "    rmse_xgb = sqrt(mean_squared_error(y_te, preds))\n",
    "    mae_xgb  = mean_absolute_error(y_te, preds)\n",
    "\n",
    "    print(f\"Number of lags (lookback): {lookback_xgb}\")\n",
    "    print(\"=== XGBoost Test Set Performance ===\")\n",
    "    print(f\"RMSE: {rmse_xgb:.4f}, MAE: {mae_xgb:.4f}\")\n",
    "    print(\"Best XGBoost parameters:\", search_xgb.best_params_,\"\\n\")\n",
    "\n",
    "    return search_xgb, best_xgb, val_preds\n",
    "\n",
    "xgb_rand, best_xgb, y_val_pred_xgb   = run_xgb_tscv(X_train_scaled_bdf, y_btrain, X_val_scaled_bdf, y_bval, X_test_scaled_bdf, y_btest)\n",
    "\n",
    "# =====================\n",
    "# ACTUAL VS PREDICTED PLOT (XGBoost)\n",
    "# =====================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "if not isinstance(y_btest, pd.Series) or not isinstance(y_btest.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_btest is not a pandas Series with DatetimeIndex. Plotting might fail.\")\n",
    "    if 'X_test_scaled_bdf' in locals() and isinstance(X_test_scaled_bdf, pd.DataFrame) and isinstance(X_test_scaled_bdf.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_bdf.index\n",
    "         print(\"Using index from X_test_scaled_bdf for plotting.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for plotting.\")\n",
    "else:\n",
    "    test_index = y_btest.index\n",
    "\n",
    "preds = best_xgb.predict(X_test_scaled_bdf)\n",
    "\n",
    "y_bpred_array = np.asarray(preds)\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'Actual': y_btest.values,\n",
    "    'Predicted': y_bpred_array\n",
    "}, index=test_index)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(plot_df.index, plot_df['Actual'],\n",
    "         label='Actual Price', color='black', linewidth=2)\n",
    "plt.plot(plot_df.index, plot_df['Predicted'],\n",
    "         label='Predicted (XGBoost)', color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.title('BRENT Crude Oil: Actual vs Predicted Prices (XGBoost)', fontsize=14)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(DateFormatter('%Y-%m'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== XGBoost Test Set Performance ===\")\n",
    "print(f\"RMSE: {sqrt(mean_squared_error(y_btest, y_bpred_array)):.4f}\")\n",
    "print(f\"MAE : {mean_absolute_error(y_btest, y_bpred_array):.4f}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_btest, pd.Series) or not isinstance(y_btest.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_btest is not a pandas Series with DatetimeIndex. Cannot create plot_bdf.\")\n",
    "    # Attempt to use index from X_test_scaled_df if available\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_bdf, pd.DataFrame) and isinstance(X_test_scaled_bdf.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_bdf.index\n",
    "         print(\"Using index from X_test_scaled_df for DataFrame.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for creating the DataFrame.\")\n",
    "else:\n",
    "    test_index = y_btest.index\n",
    "\n",
    "# Ensure y_pred is available as a numpy array or list\n",
    "if 'preds' not in locals():\n",
    "    raise ValueError(\"preds (predictions) are not available. Please run the PSO-LGBM prediction cell first.\")\n",
    "\n",
    "# Create a DataFrame with Actual and Predicted values using the correct index\n",
    "results_bdf = pd.DataFrame({\n",
    "    'Date': test_index,\n",
    "    'Predicted_Price_LGBM': preds\n",
    "})\n",
    "\n",
    "# Set 'Date' as the index for better representation, though not strictly necessary for CSV export\n",
    "results_bdf = results_bdf.set_index('Date')\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_path = '/content/drive/MyDrive/FYP PROJECT/BRENT_XGBoost_DataPredictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_bdf.to_csv(csv_path)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n",
    "display(results_bdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65rqqEOL-alN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f18256d2"
   },
   "source": [
    "**Reasoning**:\n",
    "The error indicates that the data variables (X_train_scaled_df, y_train, X_val_scaled_df, y_val) are not defined in the current session. This is likely because the notebook state was reset or the cells defining these variables were not executed in the current environment. The `lgbm_objective` function relies on these variables being available in the global scope. The code to define these variables is present in cell `A0OmHNi74R50`. I will re-execute the cell that defines and prepares the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c900bcd"
   },
   "source": [
    "**Reasoning**:\n",
    "The traceback indicates that the `wti_clean` DataFrame is not defined, which is required for the data preparation step. This means the cell that loads and cleans the WTI data (`hF3acd2KyWv_`) was not executed. I will re-execute the cell that loads and cleans the WTI data to ensure `wti_clean` is available.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74f790ad",
    "outputId": "9db9e56f-07ae-4a5c-fbf6-6d67e17a40d0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure wti_clean is available and has the 'Price' column\n",
    "if 'wti_clean' not in locals() or 'Price' not in wti_clean.columns:\n",
    "    print(\"Error: wti_clean DataFrame with 'Price' column is required.\")\n",
    "else:\n",
    "    # Use the original wti_clean data for plotting the actual prices\n",
    "    price_series = wti_clean['Price']\n",
    "\n",
    "    # Get the indices (dates) for each split from the scaled dataframes\n",
    "    if 'X_train_scaled_df' in locals() and 'X_val_scaled_df' in locals() and 'X_test_scaled_df' in locals():\n",
    "        train_index = X_train_scaled_df.index\n",
    "        val_index = X_val_scaled_df.index\n",
    "        test_index = X_test_scaled_df.index\n",
    "\n",
    "        plt.figure(figsize=(14, 6))\n",
    "\n",
    "        # Plot the training set\n",
    "        plt.plot(price_series.loc[train_index].index, price_series.loc[train_index].values, label='Training Set', color='blue')\n",
    "\n",
    "        # Plot the validation set\n",
    "        plt.plot(price_series.loc[val_index].index, price_series.loc[val_index].values, label='Validation Set', color='green')\n",
    "\n",
    "        # Plot the test set\n",
    "        plt.plot(price_series.loc[test_index].index, price_series.loc[test_index].values, label='Test Set', color='red')\n",
    "\n",
    "        plt.title('WTI Crude Oil Price Time Series Split')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Scaled dataframes (X_train_scaled_df, X_val_scaled_df, X_test_scaled_df) are required for plotting the split.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "392044d0",
    "outputId": "813d6cf9-7440-45a0-fd5d-50a354c9bcbe"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure wti_clean is available and has the 'Price' column\n",
    "if 'wti_clean' not in locals() or 'Price' not in wti_clean.columns:\n",
    "    print(\"Error: wti_clean DataFrame with 'Price' column is required for plotting the split.\")\n",
    "else:\n",
    "    # Use the original wti_clean data for plotting the actual prices\n",
    "    price_series = wti_clean['Price']\n",
    "\n",
    "    # Get the indices (dates) for each split from the scaled dataframes\n",
    "    if 'X_train_scaled_df' in locals() and 'X_val_scaled_df' in locals() and 'X_test_scaled_df' in locals():\n",
    "        train_index = X_train_scaled_df.index\n",
    "        val_index = X_val_scaled_df.index\n",
    "        test_index = X_test_scaled_df.index\n",
    "\n",
    "        plt.figure(figsize=(14, 6))\n",
    "\n",
    "        # Plot the training set\n",
    "        plt.plot(price_series.loc[train_index].index, price_series.loc[train_index].values, label='Training Set', color='blue')\n",
    "\n",
    "        # Plot the validation set\n",
    "        plt.plot(price_series.loc[val_index].index, price_series.loc[val_index].values, label='Validation Set', color='green')\n",
    "\n",
    "        # Plot the test set\n",
    "        plt.plot(price_series.loc[test_index].index, price_series.loc[test_index].values, label='Test Set', color='red')\n",
    "\n",
    "        plt.title('WTI Crude Oil Price Time Series Split Visualization')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Scaled dataframes (X_train_scaled_df, X_val_scaled_df, X_test_scaled_df) are required for plotting the split visualization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "00350b57",
    "outputId": "9f72c0a4-e3e6-4223-a5f0-9778d6846246"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure y_test is a pandas Series with a DatetimeIndex\n",
    "if not isinstance(y_test, pd.Series) or not isinstance(y_test.index, pd.DatetimeIndex):\n",
    "    print(\"Warning: y_test is not a pandas Series with DatetimeIndex. Cannot create plot_df.\")\n",
    "    # Attempt to use index from X_test_scaled_df if available\n",
    "    if 'X_test_scaled_df' in locals() and isinstance(X_test_scaled_df, pd.DataFrame) and isinstance(X_test_scaled_df.index, pd.DatetimeIndex):\n",
    "         test_index = X_test_scaled_df.index\n",
    "         print(\"Using index from X_test_scaled_df for DataFrame.\")\n",
    "    else:\n",
    "         raise TypeError(\"Could not find a suitable DatetimeIndex for creating the DataFrame.\")\n",
    "else:\n",
    "    test_index = y_test.index\n",
    "\n",
    "# Ensure y_pred is available as a numpy array or list\n",
    "if 'y_pred' not in locals():\n",
    "    raise ValueError(\"y_pred (predictions) are not available. Please run the PSO-LGBM prediction cell first.\")\n",
    "\n",
    "# Create a DataFrame with Actual and Predicted values using the correct index\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': test_index,\n",
    "    'Predicted_Price_LGBM': y_pred\n",
    "})\n",
    "\n",
    "# Set 'Date' as the index for better representation, though not strictly necessary for CSV export\n",
    "results_df = results_df.set_index('Date')\n",
    "\n",
    "# Define the path to save the CSV file\n",
    "csv_path = '/content/drive/MyDrive/FYP PROJECT/WTI_PSO_LGBM_Predictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(csv_path)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n",
    "display(results_df.head())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOwqhGdwCxnBkc05g3J29NV",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
